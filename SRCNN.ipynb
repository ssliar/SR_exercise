{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCNN pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "from os.path import exists, join, basename\n",
    "from os import remove\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "from torchvision.transforms import Compose, CenterCrop, ToTensor,Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## createdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('YCbCr')\n",
    "    y, _, _ = img.split()\n",
    "    return y\n",
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self, image_dir, input_transform=None, target_transform=None):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n",
    "\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "    def __getitem__(self, index):\n",
    "        input_image = load_img(self.image_filenames[index])\n",
    "        target = input_image.copy()\n",
    "        if self.input_transform:\n",
    "            input_image = self.input_transform(input_image)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "        return input_image, target\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_bsd300(dest=\"./dataset\"):\n",
    "    output_image_dir = join(dest, \"BSDS300/images\")\n",
    "\n",
    "    if not exists(output_image_dir):\n",
    "        url = \"http://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz\"\n",
    "        print(\"downloading url \", url)\n",
    "        data = urllib.request.urlopen(url)\n",
    "        file_path = join(dest, basename(url))\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(data.read())\n",
    "        print(\"Extracting data\")\n",
    "        with tarfile.open(file_path) as tar:\n",
    "            for item in tar:\n",
    "                tar.extract(item, dest)\n",
    "        remove(file_path)\n",
    "    return output_image_dir\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "def input_transform(crop_size, upscale_factor):\n",
    "    return Compose([\n",
    "        CenterCrop(crop_size),\n",
    "        Scale(crop_size // upscale_factor),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "def target_transform(crop_size):\n",
    "    return Compose([\n",
    "        CenterCrop(crop_size),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_training_set(upscale_factor):\n",
    "    root_dir = download_bsd300()\n",
    "    train_dir = join(root_dir, \"train\")\n",
    "    crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
    "\n",
    "    return DatasetFromFolder(train_dir,\n",
    "                             input_transform=input_transform(crop_size, upscale_factor),\n",
    "                             target_transform=target_transform(crop_size))\n",
    "\n",
    "def get_test_set(upscale_factor):\n",
    "    root_dir = download_bsd300()\n",
    "    test_dir = join(root_dir, \"test\")\n",
    "    crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
    "\n",
    "    return DatasetFromFolder(test_dir,\n",
    "                             input_transform=input_transform(crop_size, upscale_factor),\n",
    "                             target_transform=target_transform(crop_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_channels, base_filter, upscale_factor=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channels, out_channels=base_filter, kernel_size=9, stride=1, padding=4,\n",
    "                      bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=base_filter, out_channels=base_filter // 2, kernel_size=5, stride=1, padding=2,\n",
    "                      bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=base_filter // 2, out_channels=num_channels * (upscale_factor ** 2), kernel_size=5, stride=1, padding=2,\n",
    "                      bias=True),\n",
    "            nn.PixelShuffle(upscale_factor)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "TOTAL_BAR_LENGTH = 80\n",
    "LAST_T = time.time()\n",
    "BEGIN_T = LAST_T\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global LAST_T, BEGIN_T\n",
    "    if current == 0:\n",
    "        BEGIN_T = time.time()  # Reset for new bar.\n",
    "\n",
    "    current_len = int(TOTAL_BAR_LENGTH * (current + 1) / total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - current_len) - 1\n",
    "\n",
    "    sys.stdout.write(' %d/%d' % (current + 1, total))\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(current_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    current_time = time.time()\n",
    "    step_time = current_time - LAST_T\n",
    "    LAST_T = current_time\n",
    "    total_time = current_time - BEGIN_T\n",
    "\n",
    "    time_used = '  Step: %s' % format_time(step_time)\n",
    "    time_used += ' | Tot: %s' % format_time(total_time)\n",
    "    if msg:\n",
    "        time_used += ' | ' + msg\n",
    "\n",
    "    msg = time_used\n",
    "    sys.stdout.write(msg)\n",
    "\n",
    "    if current < total - 1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "# return the formatted time\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    seconds_final = int(seconds)\n",
    "    seconds = seconds - seconds_final\n",
    "    millis = int(seconds*1000)\n",
    "    output = ''\n",
    "    time_index = 1\n",
    "    if days > 0:\n",
    "        output += str(days) + 'D'\n",
    "        time_index += 1\n",
    "    if hours > 0 and time_index <= 2:\n",
    "        output += str(hours) + 'h'\n",
    "        time_index += 1\n",
    "    if minutes > 0 and time_index <= 2:\n",
    "        output += str(minutes) + 'm'\n",
    "        time_index += 1\n",
    "    if seconds_final > 0 and time_index <= 2:\n",
    "        output += str(seconds_final) + 's'\n",
    "        time_index += 1\n",
    "    if millis > 0 and time_index <= 2:\n",
    "        output += str(millis) + 'ms'\n",
    "        time_index += 1\n",
    "    if output == '':\n",
    "        output = '0ms'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log10\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "#from SRCNN.model import Net\n",
    "#from misc import progress_bar  记录时间\n",
    "class SRCNNTrainer(object):\n",
    "    def __init__(self, training_loader, testing_loader):\n",
    "        self.model = None\n",
    "        self.lr = 0.01\n",
    "        self.nEpochs = 10\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        #self.GPU_IN_USE = torch.cuda.is_available()\n",
    "        self.seed = 123\n",
    "        self.upscale_factor = 4\n",
    "        self.training_loader = training_loader\n",
    "        self.testing_loader = testing_loader\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = Net(num_channels=1, base_filter=64, upscale_factor=self.upscale_factor)\n",
    "        self.model.weight_init(mean=0.0, std=0.01)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        torch.manual_seed(self.seed)\n",
    "\n",
    "        #if self.GPU_IN_USE:\n",
    "            #torch.cuda.manual_seed(self.seed)\n",
    "            #self.model.cuda()\n",
    "            #cudnn.benchmark = True\n",
    "            #self.criterion.cuda()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.scheduler = lr_scheduler.MultiStepLR(self.optimizer, milestones=[50, 75, 100], gamma=0.5)  # lr decay\n",
    "\n",
    "    def save(self):\n",
    "        model_out_path = \"SRCNN_model_path.pth\"\n",
    "        torch.save(self.model, model_out_path)\n",
    "        print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        data: [torch.cuda.FloatTensor], 4 batches: [64, 64, 64, 8]\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "        for batch_num, (data, target) in enumerate(self.training_loader):\n",
    "            #if self.GPU_IN_USE:\n",
    "                #data, target = Variable(data).cuda(), Variable(target).cuda()\n",
    "            data = Variable(data)\n",
    "            target = Variable(target)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.criterion(self.model(data), target)\n",
    "            train_loss += loss.data[0]\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            progress_bar(batch_num, len(self.training_loader), 'Loss: %.4f' % (train_loss / (batch_num + 1)))\n",
    "\n",
    "        print(\"Average Loss: {:.4f}\".format(train_loss / len(self.training_loader)))\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        data: [torch.cuda.FloatTensor], 10 batches: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        avg_psnr = 0\n",
    "        for batch_num, (data, target) in enumerate(self.testing_loader):\n",
    "            #if self.GPU_IN_USE:\n",
    "                #data, target = Variable(data).cuda(), Variable(target).cuda()\n",
    "            data = Variable(data)\n",
    "            target = Variable(target)\n",
    "            prediction = self.model(data)\n",
    "            mse = self.criterion(prediction, target)\n",
    "            psnr = 10 * log10(1 / mse.data[0])\n",
    "            avg_psnr += psnr\n",
    "            progress_bar(batch_num, len(self.testing_loader), 'PSNR: %.4f' % (avg_psnr / (batch_num + 1)))\n",
    "        print(\"Average PSNR: {:.4f} dB\".format(avg_psnr / len(self.testing_loader)))\n",
    "\n",
    "    def validate(self):\n",
    "        self.build_model()\n",
    "        for epoch in range(1, self.nEpochs + 1):\n",
    "            print(\"\\n===> Epoch {} starts:\".format(epoch))\n",
    "            self.train()\n",
    "            self.test()\n",
    "            self.scheduler.step(epoch)\n",
    "            if epoch == self.nEpochs:\n",
    "                self.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> Epoch 1 starts:\n",
      " 7/7 [================================================================================>]  Step: 868ms | Tot: 16s633ms | Loss: 8.076089\n",
      "    Average Loss: 8.0760\n",
      " 100/100 [================================================================================>]  Step: 80ms | Tot: 7s596ms | PSNR: 6.2543>.......................................................................]  Step: 117ms | Tot: 786ms | PSNR: 5.3543...........................................................]  Step: 62ms | Tot: 1s264ms | PSNR: 5.3467========>........................................]  Step: 81ms | Tot: 3s751ms | PSNR: 6.1216=============>.......................................]  Step: 66ms | Tot: 3s818ms | PSNR: 6.1424==========>................................]  Step: 72ms | Tot: 4s497ms | PSNR: 6.2154 [================================================>...............................]  Step: 74ms | Tot: 4s572ms | PSNR: 6.2286\n",
      "    Average PSNR: 6.2543 dB\n",
      "\n",
      "===> Epoch 2 starts:\n",
      " 7/7 [================================================================================>]  Step: 1s21ms | Tot: 15s731ms | Loss: 0.2511\n",
      "    Average Loss: 0.2511\n",
      " 100/100 [================================================================================>]  Step: 73ms | Tot: 7s666ms | PSNR: 6.2808............................]  Step: 73ms | Tot: 1s818ms | PSNR: 5.2510..................................................]  Step: 59ms | Tot: 2s584ms | PSNR: 5.5614======>...................................................]  Step: 85ms | Tot: 2s670ms | PSNR: 5.5742=======================================>....................................]  Step: 77ms | Tot: 4s240ms | PSNR: 6.2207.............]  Step: 59ms | Tot: 4s958ms | PSNR: 6.3193.........]  Step: 64ms | Tot: 5s528ms | PSNR: 6.3122........]  Step: 78ms | Tot: 5s606ms | PSNR: 6.3318=================================>..................]  Step: 64ms | Tot: 5s873ms | PSNR: 6.3096\n",
      "    Average PSNR: 6.2808 dB\n",
      "\n",
      "===> Epoch 3 starts:\n",
      " 7/7 [================================================================================>]  Step: 874ms | Tot: 17s223ms | Loss: 0.24355\n",
      "    Average Loss: 0.2435\n",
      " 100/100 [================================================================================>]  Step: 84ms | Tot: 7s324ms | PSNR: 6.4734======>................................................................]  Step: 80ms | Tot: 1s290ms | PSNR: 5.4224 [================>...............................................................]  Step: 59ms | Tot: 1s350ms | PSNR: 5.2991....................................]  Step: 64ms | Tot: 1s857ms | PSNR: 5.6176=======================>...............]  Step: 69ms | Tot: 5s923ms | PSNR: 6.4720==============================================================>.............]  Step: 69ms | Tot: 6s52ms | PSNR: 6.4482===>]  Step: 66ms | Tot: 7s240ms | PSNR: 6.4357\n",
      "    Average PSNR: 6.4734 dB\n",
      "\n",
      "===> Epoch 4 starts:\n",
      " 7/7 [================================================================================>]  Step: 850ms | Tot: 16s351ms | Loss: 0.23515\n",
      "    Average Loss: 0.2351\n",
      " 100/100 [================================================================================>]  Step: 58ms | Tot: 7s380ms | PSNR: 6.7729....................................................................]  Step: 58ms | Tot: 868ms | PSNR: 5.5604========>..................................................................]  Step: 64ms | Tot: 1s216ms | PSNR: 5.6813.................]  Step: 68ms | Tot: 2s354ms | PSNR: 6.0317...]  Step: 81ms | Tot: 2s436ms | PSNR: 6.0599=>....................................]  Step: 57ms | Tot: 3s974ms | PSNR: 6.7053======================>.....................]  Step: 64ms | Tot: 5s460ms | PSNR: 6.8221....]  Step: 65ms | Tot: 6s480ms | PSNR: 6.7148\n",
      "    Average PSNR: 6.7729 dB\n",
      "\n",
      "===> Epoch 5 starts:\n",
      " 7/7 [================================================================================>]  Step: 897ms | Tot: 16s656ms | Loss: 0.22114\n",
      "    Average Loss: 0.2211\n",
      " 100/100 [==============================================================================>]  Step: 64ms | Tot: 7s309ms | PSNR: 7.1049............................................................]  Step: 63ms | Tot: 372ms | PSNR: 5.8629..........................................................]  Step: 73ms | Tot: 514ms | PSNR: 6.0829........]  Step: 62ms | Tot: 639ms | PSNR: 6.1813..........................]  Step: 65ms | Tot: 704ms | PSNR: 5.9676 [=========>......................................................................]  Step: 70ms | Tot: 775ms | PSNR: 5.8888...............]  Step: 63ms | Tot: 1s777ms | PSNR: 6.0691=============================>.......................................]  Step: 67ms | Tot: 3s594ms | PSNR: 7.0126==========================>.......................................]  Step: 65ms | Tot: 3s660ms | PSNR: 7.0412 [=========================================>......................................]  Step: 69ms | Tot: 3s729ms | PSNR: 7.0499 [===========================================>....................................]  Step: 64ms | Tot: 3s865ms | PSNR: 7.0714=====>...................................]  Step: 62ms | Tot: 3s928ms | PSNR: 7.0575============================================>...................................]  Step: 70ms | Tot: 3s998ms | PSNR: 7.1010=================>]  Step: 65ms | Tot: 7s375ms | PSNR: 7.1457\n",
      "    Average PSNR: 7.1457 dB\n",
      "\n",
      "===> Epoch 6 starts:\n",
      " 7/7 [================================================================================>]  Step: 863ms | Tot: 15s28ms | Loss: 0.199528\n",
      "    Average Loss: 0.1995\n",
      " 100/100 [================================================================================>]  Step: 66ms | Tot: 6s931ms | PSNR: 7.5678==========>...................................................................]  Step: 61ms | Tot: 1s30ms | PSNR: 6.5383.............]  Step: 64ms | Tot: 1s95ms | PSNR: 6.3896.........................]  Step: 69ms | Tot: 1s610ms | PSNR: 6.3880.........]  Step: 68ms | Tot: 2s77ms | PSNR: 6.7002........................]  Step: 71ms | Tot: 2s209ms | PSNR: 6.7853=>....................................................]  Step: 65ms | Tot: 2s275ms | PSNR: 6.7329..........]  Step: 69ms | Tot: 2s460ms | PSNR: 6.9347............................]  Step: 61ms | Tot: 2s589ms | PSNR: 6.9924====>...............................................]  Step: 73ms | Tot: 2s729ms | PSNR: 6.9975..........................................]  Step: 59ms | Tot: 2s999ms | PSNR: 7.2035=======================>...........................................]  Step: 82ms | Tot: 3s82ms | PSNR: 7.2735===>..........................................]  Step: 54ms | Tot: 3s137ms | PSNR: 7.3447....................]  Step: 63ms | Tot: 4s445ms | PSNR: 7.5978================================>.......................]  Step: 75ms | Tot: 4s703ms | PSNR: 7.6227================================>.....................]  Step: 69ms | Tot: 4s904ms | PSNR: 7.6116================================================>............]  Step: 69ms | Tot: 5s765ms | PSNR: 7.4992==========================================================================>.....]  Step: 77ms | Tot: 6s465ms | PSNR: 7.5519================================>...]  Step: 56ms | Tot: 6s657ms | PSNR: 7.5541\n",
      "    Average PSNR: 7.5678 dB\n",
      "\n",
      "===> Epoch 7 starts:\n",
      " 7/7 [================================================================================>]  Step: 863ms | Tot: 16s291ms | Loss: 0.18149\n",
      "    Average Loss: 0.1814\n",
      " 100/100 [================================================================================>]  Step: 61ms | Tot: 7s168ms | PSNR: 8.0235...............]  Step: 53ms | Tot: 1s362ms | PSNR: 6.7952..................................]  Step: 86ms | Tot: 1s809ms | PSNR: 6.7894...............................................]  Step: 87ms | Tot: 2s80ms | PSNR: 7.0502.........................................]  Step: 71ms | Tot: 3s8ms | PSNR: 7.4379...........]  Step: 69ms | Tot: 3s193ms | PSNR: 7.4708 [======================================>.........................................]  Step: 65ms | Tot: 3s581ms | PSNR: 7.7704 [========================================>.......................................]  Step: 63ms | Tot: 3s724ms | PSNR: 7.8622....................]  Step: 55ms | Tot: 4s313ms | PSNR: 7.9551=======================================>.............................]  Step: 76ms | Tot: 4s573ms | PSNR: 8.0379=======================================>...........]  Step: 68ms | Tot: 6s196ms | PSNR: 7.9259=========================================================================>......]  Step: 68ms | Tot: 6s605ms | PSNR: 8.0080========================================================>.....]  Step: 72ms | Tot: 6s677ms | PSNR: 8.0057 [===========================================================================>....]  Step: 60ms | Tot: 6s737ms | PSNR: 7.9906==================================================================>...]  Step: 77ms | Tot: 6s874ms | PSNR: 8.0084\n",
      "    Average PSNR: 8.0235 dB\n",
      "\n",
      "===> Epoch 8 starts:\n",
      " 7/7 [================================================================================>]  Step: 847ms | Tot: 14s866ms | Loss: 0.16711\n",
      "    Average Loss: 0.1671\n",
      " 100/100 [================================================================================>]  Step: 90ms | Tot: 7s146ms | PSNR: 8.4975........]  Step: 76ms | Tot: 1s966ms | PSNR: 7.4263..........]  Step: 60ms | Tot: 3s84ms | PSNR: 7.8439========>.........................................]  Step: 75ms | Tot: 3s531ms | PSNR: 8.2175======>.......................................]  Step: 61ms | Tot: 3s653ms | PSNR: 8.3172 [========================================>.......................................]  Step: 72ms | Tot: 3s725ms | PSNR: 8.3490 [==========================================>.....................................]  Step: 76ms | Tot: 3s859ms | PSNR: 8.3720==========>...........................]  Step: 55ms | Tot: 4s728ms | PSNR: 8.5385.........]  Step: 50ms | Tot: 5s289ms | PSNR: 8.5298\n",
      "    Average PSNR: 8.4975 dB\n",
      "\n",
      "===> Epoch 9 starts:\n",
      " 7/7 [================================================================================>]  Step: 851ms | Tot: 15s9ms | Loss: 0.1492506\n",
      "    Average Loss: 0.1492\n",
      " 100/100 [================================================================================>]  Step: 57ms | Tot: 6s872ms | PSNR: 8.9824........................................................................]  Step: 51ms | Tot: 437ms | PSNR: 7.1947..............................................................]  Step: 75ms | Tot: 847ms | PSNR: 7.5102==========================================>...]  Step: 50ms | Tot: 6s560ms | PSNR: 8.9574========================================>.]  Step: 75ms | Tot: 6s757ms | PSNR: 8.9368\n",
      "    Average PSNR: 8.9824 dB\n",
      "\n",
      "===> Epoch 10 starts:\n",
      " 7/7 [================================================================================>]  Step: 963ms | Tot: 15s383ms | Loss: 0.13813\n",
      "    Average Loss: 0.1381\n",
      " 100/100 [================================================================================>]  Step: 61ms | Tot: 7s362ms | PSNR: 9.4639.......]  Step: 97ms | Tot: 106ms | PSNR: 9.6032...............................................................]  Step: 78ms | Tot: 1s347ms | PSNR: 8.0776..................................]  Step: 63ms | Tot: 2s490ms | PSNR: 8.4542========>..................................]  Step: 66ms | Tot: 4s221ms | PSNR: 9.2834.........]  Step: 64ms | Tot: 4s351ms | PSNR: 9.3501===========================>...............................]  Step: 68ms | Tot: 4s419ms | PSNR: 9.3558..............................]  Step: 66ms | Tot: 4s485ms | PSNR: 9.3813 [==================================================================>.............]  Step: 67ms | Tot: 6s157ms | PSNR: 9.3877 [===================================================================>............]  Step: 68ms | Tot: 6s225ms | PSNR: 9.3534=====================================>...........]  Step: 73ms | Tot: 6s368ms | PSNR: 9.3299========================================================================>...]  Step: 76ms | Tot: 7s21ms | PSNR: 9.4365\n",
      "    Average PSNR: 9.4639 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liar/anaconda3/envs/python3/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to SRCNN_model_path.pth\n"
     ]
    }
   ],
   "source": [
    "train_set = get_training_set(4)\n",
    "test_set = get_test_set(4)\n",
    "training_data_loader = data.DataLoader(dataset=train_set, batch_size=32, shuffle=True)\n",
    "testing_data_loader = data.DataLoader(dataset=test_set, batch_size=1, shuffle=False)\n",
    "model = SRCNNTrainer(training_data_loader, testing_data_loader)\n",
    "model.validate()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
